{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39762d84-42a1-4d9f-a53a-717261b1f779",
   "metadata": {},
   "source": [
    "Q1. Define overfitting and underfitting in machine learning. What are the consequences of each, and how can they be mitigated?\n",
    "\n",
    "Ans - \n",
    "\n",
    "**Overfitting:** \n",
    "- It's like memorizing answers for a test but not understanding the concepts.\n",
    "- In ML, it's when a model learns the training data too well, including noise and outliers, but struggles with new, unseen data.\n",
    "- Messes up on new data because it got too cozy with the training set.\n",
    "- **Mitigation :** Use tricks like regularization, cross-validation, and tone down the model complexity to stop it from overdoing it.\n",
    "\n",
    "**Underfitting:** \n",
    "- It's like not studying enough for a test. \n",
    "- In ML, it's when a model is too simple and can't grasp the complexities of the data, performing poorly on both training and new data.\n",
    "- Doesn't learn enough, stumbles on both the training set and new data.\n",
    "- **Mitigation :** Make the model more complex, throw in more useful features, or try a fancier algorithm to fix its simplicity.\n",
    "---\n",
    "\n",
    "Q2. How can we reduce overfitting? Explain in brief.\n",
    "\n",
    "Ans - We can reduce overfitting by:\n",
    "\n",
    "- **Regularization:** Restrain complex models.\n",
    "- **Cross-validation:** Evaluate on different data splits.\n",
    "- **Simplify model:** Use fewer features or simpler algorithms.\n",
    "---\n",
    "\n",
    "Q3. Explain underfitting. List scenarios where underfitting can occur in ML.\n",
    "\n",
    "Ans - \n",
    "\n",
    "**Underfitting :**\n",
    "- Underfitting is a scenario, when a machine learning model is too simple and fails to capture the underlying patterns in the training data.\n",
    "- In ML, it's when a model is too simple and can't grasp the complexities of the data, performing poorly on both training and new data.\n",
    "- It's like not studying enough for a test. \n",
    "\n",
    "**Senarios where underfitting can occur in ML :**\n",
    "- Predicting house prices based only on the number of rooms.\n",
    "- Using a simple model for predicting student grades based on study hours.\n",
    "- Training a model on only a few cat pictures.\n",
    "\n",
    "---\n",
    "Q5: Discuss some common methods for detecting overfitting and underfitting in machine learning models. How can you determine whether your model is overfitting or underfitting?\n",
    "\n",
    "Ans - \n",
    "\n",
    "**Some common methods for detecting overfitting and underfitting in machine learning models:**\n",
    "- **Cross-validation:** Split your data into multiple folds, train the model on different subsets, and check consistency in performance.\n",
    "- **Regularization:** If using regularization, monitor the impact on performance as you adjust the regularization strength.\n",
    "- **Ensemble Methods:** Compare the performance of individual models to an ensemble (combination) of models.\n",
    "\n",
    "**1. We can determine whether the model is overfitting or not by,**\n",
    "- Checking how well our model is performing on a separate validation dataset, if performance is significantly worse on validation data compared to training data, it might be overfitting.\n",
    "- Plot the model's performance on training and validation sets during training, if the training performance improves while the validation performance degrades, it might be overfitting.\n",
    "\n",
    "**2. We can determine whether the model is underfitting or not by,**\n",
    "- Checking how well our model performing on the training dataset, if it performs poorly even on training data, it might be underfitting.\n",
    "- If both training and validation performance are consistently low, our model might be too simple, and it might be underfitting.\n",
    "---\n",
    "\n",
    "Q6: Compare and contrast bias and variance in machine learning. What are some examples of high bias and high variance models, and how do they differ in terms of their performance?\n",
    "\n",
    "Ans - \n",
    "\n",
    "**Bias in Machine Learning :**\n",
    "- Bias is considered a systematic error that occurs in the machine learning model itself due to incorrect assumptions in the ML process.\n",
    "- It's also known as algorithm bias or AI bias. \n",
    "- Bias is the error between the average model prediction and the ground truth.\n",
    "- If the bias is very big, the model may be overly sensitive to the data and could result in inaccurate predictions. \n",
    "- Biased datasets can result in skewed outcomes, low accuracy levels, analytical errors and it leads to poor performance on both training and unseen data. \n",
    "- Bias is about being too simple.\n",
    "- **Example:** Consider the face recognition system in the sampling bias. If the collected data contains mostly photographs of white men, then random sampling will not help avoid bias, as bias is already inherent to the collected data. This is an example of representation bias.\n",
    "\n",
    "**Variance in Machine Learning:**\n",
    "- In machine learning, variance is the amount of change in a model's performance when it's trained on different subsets of training data.\n",
    "- Variance is the variability in the model prediction â€” how much the ML function can adjust depending on the given data set. \n",
    "- Variance is about being too sensitive to the training data.\n",
    "- **Example:** A very deep and complex neural network might have high variance, as it could fit the training data extremely closely, leading to poor generalization.\n",
    "\n",
    "**High Bias Model:**\n",
    "- **Characteristics:** Too simplistic, may overlook important patterns.\n",
    "- **Performance:** Performs poorly on both training and new data; underfits the complexity of the problem.\n",
    "- **Model:** Fails to capture the complexity of the data, resulting in consistently poor performance. High bias models are too simple and perform poorly everywhere.**\n",
    "- **Example:** Linear regression with too few features.\n",
    "\n",
    "**High Variance Model:**\n",
    "- **Characteristics:** Too complex, fits training data too closely.\n",
    "- **Performance:** Fits training data well but struggles to generalize to new, unseen data; overfits the training set.\n",
    "- **Model:** Performs well on training data but struggles with new data, indicating poor generalization. High variance models fit the training data too closely but struggle when faced with new, unseen data.**\n",
    "- **Example:** Very deep neural network.\n",
    "\n",
    "---\n",
    "\n",
    "Q7: What is regularization in machine learning, and how can it be used to prevent overfitting? Describe some common regularization techniques and how they work.\n",
    "\n",
    "Ans - \n",
    "\n",
    "**Regularization in Machine Learning :**\n",
    "- Regularization is a technique used to prevent overfitting in machine learning models. \n",
    "- Overfitting occurs when a model learns the training data too well, including its noise and outliers, leading to poor performance on new, unseen data.\n",
    "\n",
    "**Some common regularization techniques :**\n",
    "\n",
    "1. L1 Regularization (Lasso): Punishes for using too many features, encourages fewer features.\n",
    "2. L2 Regularization (Ridge): Punishes for using very big numbers, prevents large weights.\n",
    "3. Elastic Net Regularization: Combines both two punishments L1 & L2. Encourages fewer features and prevents large weights.\n",
    "4. Dropout (Neural Networks): Randomly ignores parts to prevent reliance.\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "3. **Elastic Net Regularization:**\n",
    "   - **How it works:** \n",
    "\n",
    "4. **Dropout (Neural Networks):**\n",
    "   - **How it works:** Randomly drops neurons, prevents reliance on specific features.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f95a23-6ac5-4f6f-b46a-43b6c691c744",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
