{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b79f98b8-6f47-41c1-9b69-5d7705ecab66",
   "metadata": {},
   "source": [
    "Q1. What is Min-Max scaling, and how is it used in data preprocessing? Provide an example to illustrate its application.\n",
    "\n",
    "Ans - \n",
    "\n",
    "**Min-Max Scaling (Normalization) :**\n",
    "\n",
    "- Min-Max scaling is a technique used in machine learning to rescale numerical features within a specific range.\n",
    "- The goal is to bring all the feature values into a similar scale, usually between 0 and 1, or sometimes between -1 and 1.\n",
    "- This makes it easier for the algorithm to learn patterns from the data, as features with larger magnitudes won't dominate those with smaller magnitudes.\n",
    "\n",
    "**Example :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c4f7876-55e0-4b84-bbc0-38d8a86188c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup</th>\n",
       "      <th>dropoff</th>\n",
       "      <th>passengers</th>\n",
       "      <th>distance</th>\n",
       "      <th>fare</th>\n",
       "      <th>tip</th>\n",
       "      <th>tolls</th>\n",
       "      <th>total</th>\n",
       "      <th>color</th>\n",
       "      <th>payment</th>\n",
       "      <th>pickup_zone</th>\n",
       "      <th>dropoff_zone</th>\n",
       "      <th>pickup_borough</th>\n",
       "      <th>dropoff_borough</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-03-23 20:21:09</td>\n",
       "      <td>2019-03-23 20:27:24</td>\n",
       "      <td>1</td>\n",
       "      <td>1.60</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.95</td>\n",
       "      <td>yellow</td>\n",
       "      <td>credit card</td>\n",
       "      <td>Lenox Hill West</td>\n",
       "      <td>UN/Turtle Bay South</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-03-04 16:11:55</td>\n",
       "      <td>2019-03-04 16:19:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.79</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.30</td>\n",
       "      <td>yellow</td>\n",
       "      <td>cash</td>\n",
       "      <td>Upper West Side South</td>\n",
       "      <td>Upper West Side South</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-03-27 17:53:01</td>\n",
       "      <td>2019-03-27 18:00:25</td>\n",
       "      <td>1</td>\n",
       "      <td>1.37</td>\n",
       "      <td>7.5</td>\n",
       "      <td>2.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.16</td>\n",
       "      <td>yellow</td>\n",
       "      <td>credit card</td>\n",
       "      <td>Alphabet City</td>\n",
       "      <td>West Village</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-03-10 01:23:59</td>\n",
       "      <td>2019-03-10 01:49:51</td>\n",
       "      <td>1</td>\n",
       "      <td>7.70</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.95</td>\n",
       "      <td>yellow</td>\n",
       "      <td>credit card</td>\n",
       "      <td>Hudson Sq</td>\n",
       "      <td>Yorkville West</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-03-30 13:27:42</td>\n",
       "      <td>2019-03-30 13:37:14</td>\n",
       "      <td>3</td>\n",
       "      <td>2.16</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.40</td>\n",
       "      <td>yellow</td>\n",
       "      <td>credit card</td>\n",
       "      <td>Midtown East</td>\n",
       "      <td>Yorkville West</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               pickup             dropoff  passengers  distance  fare   tip  \\\n",
       "0 2019-03-23 20:21:09 2019-03-23 20:27:24           1      1.60   7.0  2.15   \n",
       "1 2019-03-04 16:11:55 2019-03-04 16:19:00           1      0.79   5.0  0.00   \n",
       "2 2019-03-27 17:53:01 2019-03-27 18:00:25           1      1.37   7.5  2.36   \n",
       "3 2019-03-10 01:23:59 2019-03-10 01:49:51           1      7.70  27.0  6.15   \n",
       "4 2019-03-30 13:27:42 2019-03-30 13:37:14           3      2.16   9.0  1.10   \n",
       "\n",
       "   tolls  total   color      payment            pickup_zone  \\\n",
       "0    0.0  12.95  yellow  credit card        Lenox Hill West   \n",
       "1    0.0   9.30  yellow         cash  Upper West Side South   \n",
       "2    0.0  14.16  yellow  credit card          Alphabet City   \n",
       "3    0.0  36.95  yellow  credit card              Hudson Sq   \n",
       "4    0.0  13.40  yellow  credit card           Midtown East   \n",
       "\n",
       "            dropoff_zone pickup_borough dropoff_borough  \n",
       "0    UN/Turtle Bay South      Manhattan       Manhattan  \n",
       "1  Upper West Side South      Manhattan       Manhattan  \n",
       "2           West Village      Manhattan       Manhattan  \n",
       "3         Yorkville West      Manhattan       Manhattan  \n",
       "4         Yorkville West      Manhattan       Manhattan  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "df = sns.load_dataset('taxis')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e66fe24-c8db-4449-9f26-5e9925e3b56e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MinMaxScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_max = MinMaxScaler()\n",
    "min_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a52b9604-2904-4156-885c-b8b032bf8418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.06713923],\n",
       "       [0.0461042 ],\n",
       "       [0.07411249],\n",
       "       ...,\n",
       "       [0.09220839],\n",
       "       [0.03169663],\n",
       "       [0.10869064]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_max.fit_transform(df[['total']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066f7fcd-337b-4094-a355-06fa447f374e",
   "metadata": {},
   "source": [
    "---\n",
    "Q2. What is the Unit Vector technique in feature scaling, and how does it differ from Min-Max scaling? Provide an example to illustrate its application.\n",
    "\n",
    "Ans -\n",
    "\n",
    "**Unit Vector :**\n",
    "\n",
    "- The Unit Vector technique, also known as Unit Norm scaling, is a feature scaling method used to normalize data by scaling each feature so that its magnitude (length) becomes 1. \n",
    "- This technique preserves the direction of the data while ensuring that all features are on the same scale.\n",
    "- This technique used in machine learning to adjust the range of numerical features to make them easier to work with and compare.\n",
    "- Imagine you have a dataset with different features, and each feature has values that range from different minimum to maximum values.\n",
    "- For example, one feature might range from 0 to 100, while another ranges from -1000 to 1000.\n",
    "- The unit vector method works by transforming each feature so that its values fall within the same range, typically between 0 and 1.\n",
    "- Unit Vector scaling is particularly useful when the direction of the data is important and it ensures that all features have a length of 1, Min-Max scaling transforms the values of a dataset into a predefined range (typically 0 to 1).\n",
    "\n",
    "**Example :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c4328b3-0198-4d6a-a43b-67e67b6f84ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>Second</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Q</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  pclass     sex   age  sibsp  parch     fare embarked   class  \\\n",
       "0           0       3    male  22.0      1      0   7.2500        S   Third   \n",
       "1           1       1  female  38.0      1      0  71.2833        C   First   \n",
       "2           1       3  female  26.0      0      0   7.9250        S   Third   \n",
       "3           1       1  female  35.0      1      0  53.1000        S   First   \n",
       "4           0       3    male  35.0      0      0   8.0500        S   Third   \n",
       "..        ...     ...     ...   ...    ...    ...      ...      ...     ...   \n",
       "886         0       2    male  27.0      0      0  13.0000        S  Second   \n",
       "887         1       1  female  19.0      0      0  30.0000        S   First   \n",
       "888         0       3  female   NaN      1      2  23.4500        S   Third   \n",
       "889         1       1    male  26.0      0      0  30.0000        C   First   \n",
       "890         0       3    male  32.0      0      0   7.7500        Q   Third   \n",
       "\n",
       "       who  adult_male deck  embark_town alive  alone  \n",
       "0      man        True  NaN  Southampton    no  False  \n",
       "1    woman       False    C    Cherbourg   yes  False  \n",
       "2    woman       False  NaN  Southampton   yes   True  \n",
       "3    woman       False    C  Southampton   yes  False  \n",
       "4      man        True  NaN  Southampton    no   True  \n",
       "..     ...         ...  ...          ...   ...    ...  \n",
       "886    man        True  NaN  Southampton    no   True  \n",
       "887  woman       False    B  Southampton   yes   True  \n",
       "888  woman       False  NaN  Southampton    no  False  \n",
       "889    man        True    C    Cherbourg   yes   True  \n",
       "890    man        True  NaN   Queenstown    no   True  \n",
       "\n",
       "[891 rows x 15 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import normalize\n",
    "df = sns.load_dataset('titanic')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ac06550-3459-4bdd-8c00-d1662990a68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['age', 'fare'], inplace=True)  # Drop rows with NaN values in 'age' or 'fare' columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36d1b288-87d9-4393-b6aa-4c0cc4c33192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.949757</td>\n",
       "      <td>0.312988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.470417</td>\n",
       "      <td>0.882444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.956551</td>\n",
       "      <td>0.291564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.550338</td>\n",
       "      <td>0.834942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.974555</td>\n",
       "      <td>0.224148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>0.801231</td>\n",
       "      <td>0.598355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>0.901002</td>\n",
       "      <td>0.433816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>0.535052</td>\n",
       "      <td>0.844819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>0.654931</td>\n",
       "      <td>0.755689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>0.971903</td>\n",
       "      <td>0.235383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>714 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          age      fare\n",
       "0    0.949757  0.312988\n",
       "1    0.470417  0.882444\n",
       "2    0.956551  0.291564\n",
       "3    0.550338  0.834942\n",
       "4    0.974555  0.224148\n",
       "..        ...       ...\n",
       "709  0.801231  0.598355\n",
       "710  0.901002  0.433816\n",
       "711  0.535052  0.844819\n",
       "712  0.654931  0.755689\n",
       "713  0.971903  0.235383\n",
       "\n",
       "[714 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_df = pd.DataFrame(normalize(df[['age', 'fare']]), columns = ['age', 'fare'])\n",
    "normalized_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5dc809-0ced-4ba3-97ed-643cd7a67575",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca31205-39b0-47f5-9595-17fb75c024ce",
   "metadata": {},
   "source": [
    "Q3. What is PCA (Principle Component Analysis), and how is it used in dimensionality reduction? Provide an\n",
    "example to illustrate its application.\n",
    "\n",
    "Ans - \n",
    "\n",
    "**PCA (Principal Component Analysis) :**\n",
    "\n",
    "- PCA (Principal Component Analysis) is a technique used for feature extraction in machine learning and data analysis.\n",
    "- It's primarily employed to reduce the dimensionality of a dataset while preserving as much variance as possible.\n",
    "- This reduction in dimensionality can help in simplifying the dataset, making it easier to analyze, visualize, and model.\n",
    "- It is a technique to simplify complex data by finding its most important patterns. \n",
    "- It does this by transforming the data into a new set of variables called principal components. \n",
    "- These components capture the main sources of variation in the data. \n",
    "- By focusing on these key patterns, PCA helps reduce the amount of information needed to describe the data, making it easier to understand and analyze.\n",
    "- PCA is one of the most commonly used unsupervised machine learning algorithms.\n",
    "- It's used in a variety of applications, including:\n",
    "    - **Exploratory data analysis**\n",
    "    - **Dimensionality reduction**\n",
    "    - **Information compression**\n",
    "    - **Data de-noising**\n",
    "    \n",
    "**Example :**\n",
    "- Imagine you have a basket of fruits with various attributes like weight, size, color, and sweetness. \n",
    "- PCA helps simplify this complex data by finding the most important patterns, like overall size, sweetness, and color intensity. \n",
    "- By focusing on these main patterns, PCA reduces the number of features, making it easier to understand and analyze the dataset.\n",
    "\n",
    "---\n",
    "\n",
    "Q4. What is the relationship between PCA and Feature Extraction, and how can PCA be used for Feature Extraction? Provide an example to illustrate this concept.\n",
    "\n",
    "Ans - \n",
    "\n",
    "**Relationship Between PCA (Principal Component Analysis) and Feature Extraction :**\n",
    "- PCA is a feature extraction technique that simplifies data by identifying and capturing important patterns. \n",
    "- It transforms original features into new variables called principal components. \n",
    "- These components represent the most significant variations in the data. \n",
    "- By selecting a subset of principal components, PCA extracts a reduced set of informative features, improving efficiency in machine learning tasks.\n",
    "\n",
    "**PCA Be Used For Feature Extraction By :**\n",
    "- PCA helps in feature extraction by transforming the original features into a smaller set of principal components.\n",
    "- These components capture the main patterns or variations in the data. \n",
    "- By selecting a subset of these components, we effectively extract a reduced set of features that retains most of the important information while discarding less relevant details. \n",
    "- This simplified set of features can improve the performance of machine learning models by reducing noise, computational complexity, and overfitting.\n",
    "\n",
    "**Example :**\n",
    "- In a dataset about cars with features like horsepower and weight, PCA simplifies by finding main patterns, like car size and power. \n",
    "- It transforms these into fewer variables called principal components, capturing key characteristics. \n",
    "- This simplification helps analyze cars more easily.\n",
    "\n",
    "---\n",
    "\n",
    "Q5. You are working on a project to build a recommendation system for a food delivery service. The dataset contains features such as price, rating, and delivery time. Explain how you would use Min-Max scaling to preprocess the data.\n",
    "\n",
    "Ans - \n",
    "\n",
    "**How We Can Use Min-Max Scaling To Preprocess The Data :**\n",
    "- By scaling the features using Min-Max scaling, we ensure that no single feature dominates the analysis due to differences in scale. \n",
    "- This helps prevent bias and ensures that the recommendation system can effectively consider all features when making recommendations.\n",
    "- By applying Min-Max scaling to features like price and delivery time in the food delivery service dataset, we can ensure that all features are on a similar scale, making them directly comparable and facilitating analysis.\n",
    "\n",
    "**Min-Max Scaling (Normalization) :**\n",
    "- Normalization, also known as Min-Max scaling, is a technique used in machine learning to rescale numerical features within a specific range.\n",
    "- The goal is to bring all the feature values into a similar scale, usually between 0 and 1, or sometimes between -1 and 1.\n",
    "- This makes it easier for the algorithm to learn patterns from the data, as features with larger magnitudes won't dominate those with smaller magnitudes.\n",
    "- It is a preprocessing technique used to rescale numerical features within a specific range, typically between 0 and 1 or -1 and 1. \n",
    "\n",
    "**Here's How We Can Use Min-Max Scaling :**\n",
    "1. For each numerical feature (e.g. price, delivery time), identify the minimum and maximum values in the dataset.\n",
    "2. Subtract the minimum value from each data point and divide by the range (maximum value minus minimum value) to scale the feature values between 0 and 1.\n",
    "3. Optionally, you can also scale the feature values between -1 and 1 by subtracting the mean from each data point and dividing by half of the range.\n",
    "\n",
    "---\n",
    "\n",
    "Q6. You are working on a project to build a model to predict stock prices. The dataset contains many features, such as company financial data and market trends. Explain how you would use PCA to reduce the dimensionality of the dataset.\n",
    "\n",
    "Ans -\n",
    "\n",
    "**PCA simplifies data while retaining essential information, aiding in efficient model training for predicting stock prices. By applying PCA we can simplify the dataset by focusing on the most important patterns in the data. This can lead to more efficient model training, reduced computational complexity, and improved model generalization performance in predicting stock prices.**\n",
    "\n",
    "**To use PCA for dimensionality reduction in predicting stock prices, follow these steps :**\n",
    "1. **Identify Features**: Select relevant features like financial data and market trends from the dataset.\n",
    "2. **Standardize Features**: Ensure all features have zero mean and unit variance.\n",
    "3. **Apply PCA**: Use PCA to find underlying patterns and transform features into principal components.\n",
    "4. **Select Components**: Choose the number of principal components based on explained variance.\n",
    "5. **Reduce Dimensionality**: Project data onto selected principal components to reduce dimensionality.\n",
    "6. **Train Model**: Use the reduced-dimensional data to train the stock price prediction model.\n",
    "\n",
    "---\n",
    "\n",
    "Q7. For a dataset containing the following values: [1, 5, 10, 15, 20], perform Min-Max scaling to transform the values to a range of -1 to 1.\n",
    "\n",
    "Ans -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b97358f0-d299-4a59-907c-ef492e322ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataset : [ 1  5 10 15 20]\n",
      "Min-Max Scaled Dataset : [-1.         -0.57894737 -0.05263158  0.47368421  1.        ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "data = np.array([1, 5, 10, 15, 20])\n",
    "\n",
    "Min = np.min(data)\n",
    "Max = np.max(data)\n",
    "\n",
    "# Apply Min-Max scaling\n",
    "data_scaled = 2 * ((data - Min) / (Max - Min)) - 1\n",
    "\n",
    "print(\"Original Dataset :\", data)\n",
    "print(\"Min-Max Scaled Dataset :\", data_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a15359-89b8-4164-8251-a0f10f499e1b",
   "metadata": {},
   "source": [
    "---\n",
    "Q8. For a dataset containing the following features: [height, weight, age, gender, blood pressure], perform Feature Extraction using PCA. How many principal components would you choose to retain, and why?\n",
    "\n",
    "Ans -\n",
    "\n",
    "- The optimal number of principal components to perform Feature Extraction using PCA may vary depending on factors such as the complexity of the data, the specific modeling task, and computational constraints. \n",
    "- Experimentation and validation are often necessary to determine the most suitable number of components for your particular application.\n",
    "- It's crucial to understand the context of the analysis and specific goals of the project. \n",
    "    - If we're interested in physical characteristics, such as those relevant to healthcare or fitness, features like height, weight, and blood pressure may be more important.\n",
    "    - If we're focusing on demographic factors, gender and age could be more significant.\n",
    "    - In some cases, the importance of a feature may depend on its correlation with the target variable or its predictive power in a model.\n",
    "    \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972da06b-5c16-44af-bf30-7a2caff337f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffdaa5f-cd1f-47be-983b-59779d9bf20c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
